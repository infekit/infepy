{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "> This module store preprocessing funtions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from infepy.utils import read_k_file, read_csv_file, to_ls_dyna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# logger = logging.getLogger(name='preprocessing')\n",
    "# logging.basicConfig(filename=\"preprocessing.log\",filemode='w+' ,level=logging.DEBUG, force=True, format='[%(asctime)-15s] %(levelname)-8s %(filename)s %(funcName)s line %(lineno)d %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import toml\n",
    "from infepy.utils import _merge_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/chiarar/OneDrive - Chalmers/SSMT - Subject Specific Modeling Toolstack/Github/infepy/nbs\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def read_toml(  config_file= \"Config.toml\" # Path to the config file\n",
    "):\n",
    "    \"Read setting file. The File containes the relative path to source and target.\"\n",
    "    config= toml.load(config_file)\n",
    "    return config\n",
    "\n",
    "#config  = read_toml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_nodes(path_to_file:str # path to file containing source template\n",
    "               ) -> pd.DataFrame: # Numpy array of shape [n_nodes, x,y,z_displacement]\n",
    "    \"Read the nodes from the source template. The source template must be either a .key/.k file or .csv\"    \n",
    "    \n",
    "    if path_to_file.endswith('.csv') or path_to_file.endswith('.fcsv'):\n",
    "        mesh_df = read_csv_file(path_to_file)\n",
    "    elif path_to_file.endswith('.key') or path_to_file.endswith('.k'):\n",
    "        mesh_df= read_k_file(path_to_file)\n",
    "    return mesh_df\n",
    "\n",
    "        # if mesh_df = None, -> no file read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label - node id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3091310</td>\n",
       "      <td>-181.550415</td>\n",
       "      <td>145.430511</td>\n",
       "      <td>404.375488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3091330</td>\n",
       "      <td>-43.251625</td>\n",
       "      <td>196.187363</td>\n",
       "      <td>194.874634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3091332</td>\n",
       "      <td>-37.076435</td>\n",
       "      <td>219.493759</td>\n",
       "      <td>205.082413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3091333</td>\n",
       "      <td>-33.503811</td>\n",
       "      <td>176.722672</td>\n",
       "      <td>190.791733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3091334</td>\n",
       "      <td>-27.463694</td>\n",
       "      <td>215.396118</td>\n",
       "      <td>203.790085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>3182470</td>\n",
       "      <td>-47.164852</td>\n",
       "      <td>171.558502</td>\n",
       "      <td>192.754669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7827</th>\n",
       "      <td>3182472</td>\n",
       "      <td>-45.163231</td>\n",
       "      <td>170.620392</td>\n",
       "      <td>190.355927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>3183714</td>\n",
       "      <td>-35.255299</td>\n",
       "      <td>217.536606</td>\n",
       "      <td>208.970779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>3183720</td>\n",
       "      <td>-38.128960</td>\n",
       "      <td>216.646057</td>\n",
       "      <td>209.831924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>3186139</td>\n",
       "      <td>-50.200691</td>\n",
       "      <td>171.959595</td>\n",
       "      <td>193.315063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7831 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label - node id           x           y           z\n",
       "0             3091310 -181.550415  145.430511  404.375488\n",
       "1             3091330  -43.251625  196.187363  194.874634\n",
       "2             3091332  -37.076435  219.493759  205.082413\n",
       "3             3091333  -33.503811  176.722672  190.791733\n",
       "4             3091334  -27.463694  215.396118  203.790085\n",
       "...               ...         ...         ...         ...\n",
       "7826          3182470  -47.164852  171.558502  192.754669\n",
       "7827          3182472  -45.163231  170.620392  190.355927\n",
       "7828          3183714  -35.255299  217.536606  208.970779\n",
       "7829          3183720  -38.128960  216.646057  209.831924\n",
       "7830          3186139  -50.200691  171.959595  193.315063\n",
       "\n",
       "[7831 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| export\n",
    "# read_nodes(_merge_path(config['source']['path'],config['source']['filename_mesh']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_landmarks(path_to_file:str # .csv or .key file containing Landmarks\n",
    "                   )-> pd.DataFrame: # Dataframe of length [n_landmarks] divided in columns [ID - label, x,y,z]\n",
    "    \"Read the landmarks from .csv/.key/.k file.\"\n",
    "    file_exist = False\n",
    "    if path_to_file.endswith('.csv') or path_to_file.endswith('.fcsv') :\n",
    "        landmarks_df = read_csv_file(path_to_file)\n",
    "        file_exist = True\n",
    "    elif path_to_file.endswith('.key') or path_to_file.endswith('.k') :\n",
    "        landmarks_df= read_k_file(path_to_file)\n",
    "    \n",
    "    assert not landmarks_df.empty\n",
    "    return landmarks_df\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/target/landmarks_target.fcsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#| export\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m read_landmarks(_merge_path(config[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m],config[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mfilename_landmarks\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n",
      "Cell \u001b[0;32mIn [10], line 7\u001b[0m, in \u001b[0;36mread_landmarks\u001b[0;34m(path_to_file)\u001b[0m\n\u001b[1;32m      5\u001b[0m file_exist \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mif\u001b[39;00m path_to_file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m path_to_file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.fcsv\u001b[39m\u001b[39m'\u001b[39m) :\n\u001b[0;32m----> 7\u001b[0m     landmarks_df \u001b[39m=\u001b[39m read_csv_file(path_to_file)\n\u001b[1;32m      8\u001b[0m     file_exist \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39melif\u001b[39;00m path_to_file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.key\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m path_to_file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.k\u001b[39m\u001b[39m'\u001b[39m) :\n",
      "File \u001b[0;32m/mnt/c/Users/chiarar/OneDrive - Chalmers/SSMT - Subject Specific Modeling Toolstack/Github/infepy/infepy/utils.py:73\u001b[0m, in \u001b[0;36mread_csv_file\u001b[0;34m(path_to_file)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_csv_file\u001b[39m(path_to_file: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m     72\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mThis function read csv files in format id, x, y,z. to Pandas DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path_to_file) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m     74\u001b[0m         df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(fp, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, comment\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m         df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, :\u001b[39m4\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/target/landmarks_target.fcsv'"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "#read_landmarks(_merge_path(config['target']['path'],config['target']['filename_landmarks']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _check_landmarks(source: pd.DataFrame, # Source dataframe\n",
    "                    target: pd.DataFrame # Target dataframe\n",
    "                    ):\n",
    "    \"This function compares the source and target Dataframe. It performs two test: if the have same amount of landmarks and if Label/IDs are in the same order.  \"\n",
    "    assert len(source) == len(target), \"Not same amount of landmarks for source and target\"\n",
    "    \n",
    "    bool = target.iloc[:,0].values == source.iloc[:,0].values\n",
    "    assert bool.any() == True, \"Order of landmarks is not the same for target and source\"\n",
    "    \n",
    "    if bool.any() == False:\n",
    "        return [i for i,x in enumerate(bool) if x == False] # => [1, 3]\n",
    "        \n",
    "    # TO DO: return values that are false. Bool gived false and extract index. Print. \n",
    "    # Sort them\n",
    "        # if they dont match, return exception -->\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/target/landmarks_target.csv'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## | hide\n",
    "# _merge_path(config['target']['path'],config['target']['filename_landmarks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = read_landmarks(_merge_path(config['source']['path'],config['source']['filename_landmarks']))\n",
    "# print(_merge_path(config['target']['path'],config['target']['filename_landmarks']))\n",
    "# # target = read_landmarks(_merge_path(config['target']['path'],config['target']['filename_landmarks']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label - node id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100.001907</td>\n",
       "      <td>110.13913</td>\n",
       "      <td>-100.980621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label - node id           x          y           z\n",
       "0                1  100.001907  110.13913 -100.980621"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label - node id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100.001907</td>\n",
       "      <td>110.13913</td>\n",
       "      <td>-100.980621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label - node id           x          y           z\n",
       "0                2  100.001907  110.13913 -100.980621"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def write_output(morphed_mesh : np.ndarray, # Morphed mesh\n",
    "                 morphed_file: np.ndarray, #  path to directory to save the file\n",
    "                 mesh_file: np.ndarray, # path to the source mesh from read_setting()\n",
    "                 ):\n",
    "    \"Write an output file for the morphed mesh in key file format.\"    \n",
    "    if not os.path.exists(morphed_file): # write the file if doesn´t exist\n",
    "        open(morphed_file, 'w').close()\n",
    "     \n",
    "    node_indicator = False\n",
    "    idx_nodes = 0\n",
    "    # Read the file and read line by line to find *node section.\n",
    "    with open(mesh_file, 'r') as fp:\n",
    "        file_content = fp.readlines()\n",
    "    for idx_line, line in enumerate(file_content):\n",
    "        if line.startswith('*NODE'):\n",
    "            node_indicator = True\n",
    "            continue\n",
    "        if node_indicator and line.startswith('*'):\n",
    "            break\n",
    "        if node_indicator:\n",
    "            line_list = list(line)\n",
    "            line_list[8:24] = to_ls_dyna(morphed_mesh[idx_nodes, 0]) # x\n",
    "            line_list[24:40] = to_ls_dyna(morphed_mesh[idx_nodes, 1]) # y\n",
    "            line_list[40:56] = to_ls_dyna(morphed_mesh[idx_nodes, 2]) # z\n",
    "            file_content[idx_line] = ''.join(line_list)\n",
    "            idx_nodes += 1\n",
    "    with open(morphed_file, 'w') as fp:\n",
    "        for line in file_content:\n",
    "            fp.write(line)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infekit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
