{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "> This module store preprocessing funtions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "logger = logging.getLogger(name='preprocessing')\n",
    "logging.basicConfig(filename=\"preprocessing.log\",filemode='w+' ,level=logging.DEBUG, force=True, format='[%(asctime)-15s] %(levelname)-8s %(filename)s %(funcName)s line %(lineno)d %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_nodes(geometry:str # .csv or .key file containing source template\n",
    "               ) -> np.ndarray: # Numpy array of shape [n_nodes, x,y,z_displacement]\n",
    "    \"Read the nodes from the source template. The source template can be either a .key/.k file or .csv\"\n",
    "    try:\n",
    "        if geometry.endswith('.csv'):\n",
    "            pass\n",
    "        elif geometry.endswith('.key') or geometry.endswith('.k') :\n",
    "            pass\n",
    "    except:\n",
    "        logger.exception(\"Read_Nodes: No readable files\")\n",
    "    else:\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_landmarks(filename:str # .csv or .key file containing Landmarks\n",
    "                   ): # Dataframe of length [n_landmarks] divided in columns [ID/label, x,y,z]\n",
    "    \"Read the landmarks from file.\"\n",
    "    try:\n",
    "        if filename.endswith('.csv'):\n",
    "            pass\n",
    "        elif filename.endswith('.key') or filename.endswith('.k') :\n",
    "            pass\n",
    "    except:\n",
    "        logger.exception(\"Read_Landamarks - No readable files\")\n",
    "    else:\n",
    "        return \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _check_landmarks(source: pd.DataFrame, # Source dataframe\n",
    "                    target: pd.DataFrame # Target dataframe\n",
    "                    ):\n",
    "    \"This function compares the source and target Dataframe. It performs two test: if the have same amount of landmarks and if Label/IDs are in the same order.  \"\n",
    "    try:\n",
    "        assert len(source) == len(target), \"Not same amount of landmarks for source and target\"\n",
    "        \n",
    "        bool = target.iloc[:,0].values == source.iloc[:,0].values\n",
    "        assert bool.any() == True, \"Order of landmarks is not the same for target and source\"\n",
    "    except:\n",
    "        logger.exception(\"Invalid Landmarks. Need to be same size and order\")       \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('infekit')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
