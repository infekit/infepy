{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "> This module store preprocessing funtions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infepy.utils import read_k_file, read_csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "logger = logging.getLogger(name='preprocessing')\n",
    "logging.basicConfig(filename=\"preprocessing.log\",filemode='w+' ,level=logging.DEBUG, force=True, format='[%(asctime)-15s] %(levelname)-8s %(filename)s %(funcName)s line %(lineno)d %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import toml\n",
    "from infepy.utils import _merge_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def read_toml(  config_file= \"Config.toml\" # Path to the config file\n",
    "):\n",
    "    \"Read setting file. The File containes the relative path to source and target.\"\n",
    "    config= toml.load(config_file)\n",
    "    return config\n",
    "config  = read_toml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_nodes(path_to_mesh:str # .csv or .key file containing source template\n",
    "               ) -> np.ndarray: # Numpy array of shape [n_nodes, x,y,z_displacement]\n",
    "    \"Read the nodes from the source template. The source template can be either a .key/.k file or .csv\"    \n",
    "    try:\n",
    "        if path_to_mesh.endswith('.csv'):\n",
    "                mesh_df = read_csv_file(path_to_mesh)\n",
    "        elif path_to_mesh.endswith('.key') or path_to_mesh.endswith('.k'):\n",
    "            mesh_df= read_k_file(path_to_mesh)\n",
    "    except:\n",
    "        logger.exception(\"Read_Nodes: No readable files\")\n",
    "    return mesh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label - node id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591310</td>\n",
       "      <td>-181.550415</td>\n",
       "      <td>-145.430511</td>\n",
       "      <td>404.375488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3591330</td>\n",
       "      <td>-43.251625</td>\n",
       "      <td>-196.187363</td>\n",
       "      <td>194.874634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3591332</td>\n",
       "      <td>-37.076435</td>\n",
       "      <td>-219.493759</td>\n",
       "      <td>205.082413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label - node id           x           y           z\n",
       "0           591310 -181.550415 -145.430511  404.375488\n",
       "1          3591330  -43.251625 -196.187363  194.874634\n",
       "2          3591332  -37.076435 -219.493759  205.082413"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_nodes(_merge_path(config['source']['path'],config['source']['filename_mesh']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1757077712.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [11], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    elif filename.endswith('.key') or filename.endswith('.k') :\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def read_landmarks(path_to_file:str # .csv or .key file containing Landmarks\n",
    "                   ): # Dataframe of length [n_landmarks] divided in columns [ID/label, x,y,z]\n",
    "    \"Read the landmarks from file.\"\n",
    "    try:\n",
    "        if path_to_file.endswith('.csv'):\n",
    "\n",
    "                mesh_df = read_csv_file(path_to_file)\n",
    "            \n",
    "        elif path_to_file.endswith('.key') or path_to_file.endswith('.k') :\n",
    "            pass\n",
    "    except:\n",
    "        logger.exception(\"Read_Landamarks - No readable files\")\n",
    "    else:\n",
    "        return \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _check_landmarks(source: pd.DataFrame, # Source dataframe\n",
    "                    target: pd.DataFrame # Target dataframe\n",
    "                    ):\n",
    "    \"This function compares the source and target Dataframe. It performs two test: if the have same amount of landmarks and if Label/IDs are in the same order.  \"\n",
    "    try:\n",
    "        assert len(source) == len(target), \"Not same amount of landmarks for source and target\"\n",
    "        \n",
    "        bool = target.iloc[:,0].values == source.iloc[:,0].values\n",
    "        assert bool.any() == True, \"Order of landmarks is not the same for target and source\"\n",
    "        # TO DO: return values that are false. Bool gived false and extract index. Print. \n",
    "        # Sort them\n",
    "        # if they dont match, return exception -->\n",
    "    except:\n",
    "        logger.exception(\"Invalid Landmarks. Need to be same size and order\")       \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('infekit')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
